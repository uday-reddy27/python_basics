# -*- coding: utf-8 -*-
"""Word2Vec.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KeirCwM17AZP1e53Kj4hPGIA6qorEh94
"""

import gensim.downloader as api
model = api.load('fasttext-wiki-news-subwords-300')

print(model["king"])

model.most_similar("king")

model.most_similar(positive=['king', 'woman'], negative=['man'])

model.doesnt_match(["apple", "banana", "car", "mango"])

sentences = [
    ["machine", "learning", "is", "amazing"],
    ["deep", "learning", "is", "a", "subset", "of", "machine", "learning"],
    ["artificial", "intelligence", "is", "the", "future"],
    ["word2vec", "converts", "words", "into", "vectors"]
]

from gensim.models import Word2Vec
model2 = Word2Vec(sentences, vector_size=50, window=5, min_count=1, workers=4)

model2.wv["machine"]

model2.wv.most_similar("learning")

from scipy.spatial.distance import cosine
from numpy.linalg import norm

# Distance
norm(model["man"] - model["woman"])

# Cos Similarity
cosine(model["kingdom"], model["people"])

